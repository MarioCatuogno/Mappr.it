# Hadoop ecosystem
*A beginners guide to the Hadoop ecosystem*

IMG=HADOOP (Mappr.it style)
## Table of contents

- [Introduction](#introduction)

## Introduction

Talking at very high level about **Hadoop**, it can be considered as "*a software framework for storing, processing and analyzing big data*". It is:

* __distributed__: an Hadoop cluster is made up of several machines all working together
* __scalable__: if you need to store more data or if you need to process data faster, you can add more machines to the cluster
* __fault-tolerant__: as you add more machines to the cluster, the probability that one of these machine is going to fail increases, but Hadoop is designed with this assumption
* __open source__: it is overseen by the Apache Software Foundation with over 90 committers to core Hadoop (*coming from Cloudera, Facebook, Yhaoo!, Google, etc.*), hundreds of committers on other Hadoop-related projects and thousand of contributors writing features and fixing bugs

Hadoop has a large and growing ecosystem, these are some of the most common projects of Hadoop found in a **Cloudera** distribution:

IMG=HADOOP ECOSYSTEM

Hadoop works also with a lot of commercial products as well, for example in the BI/Business analytics sector, or the ETL part of data processing or databases. Some of them are:

IMG=HADOOP COMMERCIAL PRODUCTS

Hadoop is nowadays used in many industries (*organization in financial world, healthcare, manufacturing, non-profit, etc.*), some organization that use Hadoop are:

IMG=ORGANIZATION WHICH USES HADOOP



  ``` r
  install.packages("dplyr")
  install.packages("ggplot2")
  ```
